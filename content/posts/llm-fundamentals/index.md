+++
date = '2026-01-02T10:53:00+08:00'
lastmod = '2026-01-02T10:53:00+08:00'
draft = false
title = 'AI Agent 专题(一)：Transformer 与 LLMs基础概念'
slug = 'ai-agent-transformer-llm-basics'
description = '本文是 AI Agent 专题学习笔记之一，系统介绍 Transformer 架构与大语言模型（LLM）的关系，并讲解分词机制与上下文窗口等核心概念。'
keywords = ['Transformer', 'LLM', 'Large Language Models', 'Self-Attention', 'Tokenization', 'Context Window']
categories = ['AI Agent 专题', '学习笔记']
tags = ['Agent', 'LLM', 'Transformer', 'Token', 'Context Window']
+++

## Transformer Models 与 LLMs
Transformer 是一种以 **注意力（Attention）** 机制为核心的神经网络架构。它能够动态判断输入序列中不同部分的重要性，从而高效地建模上下文关系，极大提升自然语言处理任务的效果。

当 Transformer 在**海量文本数据**上进行大规模训练后，就形成了大语言模型（Large Language Models, LLMs）。
LLM 具备通用语言理解与生成能力，能够完成文本生成、问答、翻译、代码编写等多种任务。

在 AI Agent 系统中，LLM 通常扮演「大脑」的角色：Agent 向 LLM 提供任务描述和提示词，LLM 输出文本结果或行动计划，Agent 再基于这些结果执行具体操作，因此 Agent 被广泛应用在智能助手、自动化工具等场景中。

### Transformer架构概览
Transformer 是一种通用神经网络架构，广泛应用于：机器翻译、问答系统、文本摘要、语言建模等，
它的核心优势在于：通过注意力机制直接建模全局上下文关系，而不依赖顺序计算。
### 编码器-解码器架构
经典 Transformer 采用编码器–解码器架构：
- **编码器（Encoder）**：负责读取输入文本，并将其转换为高维语义表示
- **解码器（Decoder）**：基于编码器输出，逐步生成目标文本

例如在机器翻译中，编码器处理源语言句子，解码器生成目标语言翻译结果，编码器与解码器都由多层堆叠的 **自注意力层(Self-Attention Layers)** 和 **前馈网络层(Feed-Forward Layers)** 组成。

#### Self-Attention Layers
是 Transformer 的核心组件，它允许模型关注序列中任意位置的词，并根据上下文动态计算词与词之间的关联强度。
#### Feed-Forward Layers
在自注意力层后，每一层 Transformer 还包含前馈神经网络层：通常由两层全连接网络组成，用于增强模型的表达能力。

### LLM 的工作原理
LLM 主要通过 **自监督学习（Self-Supervised Learning）** 进行训练，其核心目标是：在给定上下文的情况下，预测缺失的下一个单词。通过在大规模文本数据集上的训练，LLM 逐渐学会：
- 单词与单词之间的关联
- 短语和句子的语义关系
- 语言的语法与结构模式
最终形成对自然语言的抽象表示与理解能力。

### LLM 的类型
从建模方式上看，当前主流 LLM 可以分为两类：
1. **自回归模型（Autoregressive Models）**：使用已有上下文预测下一个词，从而按顺序逐词生成文本，适合文本生成、对话、写作等任务，代表模型有 GPT 系列
2. **自编码模型（Autoencoding Models）**：将整句文本编码为语义向量表示，再用于理解、分类或匹配任务，该模型更擅长语义理解、检索、文本分析，代表模型有 BERT

### Transformer与LLM的联系与区别
- Transformer 是一种针对某一类任务（翻译、摘要等）进行优化的神经网络架构，它通过注意力机制来理解词语与上下文关系
- LLM 是基于 Transformer 架构在海量数据集上训练出的通用语言模型，目标是具备跨任务的语言理解与生成能力

## 分词
### 概述
想象你正在教一个婴儿学习阅读，你肯定不会一开始就让他读复杂的段落，而是从字母开始、再是发音、最后是字词。
与此类似，**分词（Tokenization）** 指的是在不丢失上下文的前提下，将原始文本拆解成机器更容易理解和处理的基本单元，这些基本单元称为 token。

为了更直观地理解分词的工作方式，我们来看个句子："Are you OK"，如果按单词进行分词，那么我们会得到一个由独立单词组成的数组：`["Are", "you", "OK"]`，
这种使用空格作为 token 边界的分词方式十分直接，但如果按单个字符进行分词的方式，原句子会被拆分地更细，这种方式在特定语言或某些 NLP 任务中尤其有用。
所以，单词与 token 之间并不存在固定的“兑换比例”，不同的模型或不同的分词器可能会以不同的方式对同一段文本进行分词，
一般情况下，一个较为合理的估算是：平均每个单词大约对应 1.5 个 token。

许多 LLM 会采用基于 token 的收费方式，比如 [OpenAI 的 GPT](https://openai.com/zh-Hans-CN/api/pricing/) 会对输入 token（你的提示词）和输出 token（模型回复内容）设定不同的价格。

### 分词的类型
分词方式会根据文本拆分的粒度和具体任务的需求不同而有所不同，这些方式既可以将文本拆解为完整的单词，也可以细化到字符，甚至更小的单位，当前主要有三种分词方式：
1. **词级分词（Word Tokenization）**：最常见的分词方式，它将文本拆分为一个个独立的单词，对英语这类具有清晰词边界的语言十分有效
2. **字符级分词（Character Tokenization）**：文本被拆分为单个字符，适用于缺乏明确词边界的语言，或需要进行更细粒度分析的任务
3. **子词分词（Subword Tokenization）**：文本被拆分为大于单个字符、但小于完整单词的单位

## 上下文窗口
**上下文窗口（Context Window）** 指的是 LLM 在任一时刻能够读取和处理的最大文本长度，通常以 token 为单位来衡量，更大的窗口可以让 LLM 处理更多的输入，并在每次输出时综合更多的信息。

我们可以将上下文窗口理解为 LLM 的工作记忆，它决定了模型在不遗忘早期细节的前提下，能够接收提示词、对话历史的最大长度，也决定了可一次性处理的文档或代码最大长度。
当上述内容的长度超过了上下文窗口大小时，就必须对部分输入内容进行压缩或遗忘。
值得注意的是，占用上下文窗口的内容，往往不仅是用户输入的文本，在许多场景中，LLM 还会额外收到系统提示词（System Prompt），它通常对用户是不可见的，
其目的是用于约束 LLM 的行为并控制对话的某些方面。此外，特殊字符、换行符等也会消耗一部分的上下文长度。

总的来说，增大 LLM 的上下文窗口能带来以下好处：更高的准确性、更连贯的回答、更长的对话能力等等，但同时也意味着更高的计算资源需求，即更高的成本。
